{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T00:33:49.708823Z",
     "start_time": "2024-11-21T00:33:29.280930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "SEED = 42\n",
    "n_splits = 5\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/train.csv')\n",
    "test = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/test.csv')\n",
    "sample = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/sample_submission.csv')\n",
    "\n",
    "# Utility function to process parquet files\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "\n",
    "    # Calculate descriptive statistics\n",
    "    stats = df.describe().values.reshape(-1)\n",
    "    return stats, filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname):\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    stats, indexes = zip(*results)\n",
    "    columns = [f\"stat_{i}\" for i in range(len(stats[0]))]\n",
    "    df = pd.DataFrame(stats, columns=columns)\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "\n",
    "# Load time series data\n",
    "train_ts = load_time_series(\"/Users/ad53533/Desktop/Applied ML/Project/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/Users/ad53533/Desktop/Applied ML/Project/series_test.parquet\")\n",
    "\n",
    "# Merge time series data with train and test datasets\n",
    "train = pd.merge(train, train_ts, how=\"left\", on=\"id\")\n",
    "test = pd.merge(test, test_ts, how=\"left\", on=\"id\")\n",
    "train = train.drop(\"id\", axis=1)\n",
    "test = test.drop(\"id\", axis=1)\n",
    "\n",
    "# Imputation for missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "train = pd.DataFrame(imputer.fit_transform(train), columns=train.columns)\n",
    "test = pd.DataFrame(imputer.transform(test), columns=test.columns)\n",
    "\n",
    "# Train individual regressors for PCIAT01 to PCIAT20\n",
    "def TrainML_Per_PCIAT(model_class, test_data):\n",
    "    X = train.drop([f'PCIAT{i:02d}' for i in range(1, 21)] + ['sii'], axis=1)\n",
    "    y = train[[f'PCIAT{i:02d}' for i in range(1, 21)]]\n",
    "\n",
    "    pciat_predictions_train = np.zeros_like(y)\n",
    "    pciat_predictions_test = np.zeros((len(test_data), 20))\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for pciat_idx, pciat_name in enumerate(y.columns):\n",
    "        print(f\"Training for {pciat_name}\")\n",
    "\n",
    "        oof_preds = np.zeros(len(y), dtype=float)\n",
    "        test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(SKF.split(X, y.iloc[:, pciat_idx])):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx, pciat_idx], y.iloc[val_idx, pciat_idx]\n",
    "\n",
    "            model = clone(model_class)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            oof_preds[val_idx] = model.predict(X_val)\n",
    "            test_preds[:, fold] = model.predict(test_data)\n",
    "\n",
    "        pciat_predictions_train[:, pciat_idx] = oof_preds\n",
    "        pciat_predictions_test[:, pciat_idx] = test_preds.mean(axis=1)\n",
    "\n",
    "    total_pciat_train = pciat_predictions_train.sum(axis=1)\n",
    "    total_pciat_test = pciat_predictions_test.sum(axis=1)\n",
    "\n",
    "    def map_total_to_class(total_pciat):\n",
    "        return np.where(total_pciat < 31, 0,\n",
    "                        np.where(total_pciat < 50, 1,\n",
    "                                 np.where(total_pciat < 80, 2, 3)))\n",
    "\n",
    "    train_sii_predicted = map_total_to_class(total_pciat_train)\n",
    "    test_sii_predicted = map_total_to_class(total_pciat_test)\n",
    "\n",
    "    return test_sii_predicted\n",
    "\n",
    "# Define features and categorical columns\n",
    "featuresCols = [col for col in train.columns if col not in ['id', 'sii'] + [f'PCIAT{i:02d}' for i in range(1, 21)]]\n",
    "categorical_cols = [col for col in featuresCols if train[col].dtype == 'object']\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "train = pd.get_dummies(train, columns=categorical_cols, drop_first=True)\n",
    "test = pd.get_dummies(test, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Align train and test datasets\n",
    "train_sii = train['sii']\n",
    "train, test = train.drop('sii', axis=1).align(test, join=\"outer\", axis=1, fill_value=0)\n",
    "train['sii'] = train_sii\n",
    "\n",
    "# Define an ensemble regressor\n",
    "ensemble = VotingRegressor(estimators=[\n",
    "    ('lgb', Pipeline(steps=[('imputer', SimpleImputer(strategy=\"median\")), ('regressor', LGBMRegressor(random_state=SEED))])),\n",
    "    ('xgb', Pipeline(steps=[('imputer', SimpleImputer(strategy=\"median\")), ('regressor', XGBRegressor(random_state=SEED))])),\n",
    "    ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy=\"median\")), ('regressor', CatBoostRegressor(random_state=SEED, silent=True))])),\n",
    "])\n",
    "\n",
    "# Train the model and predict\n",
    "predictions = TrainML_Per_PCIAT(ensemble, test)\n",
    "\n",
    "# Save predictions\n",
    "sample['sii'] = predictions\n",
    "sample.to_csv('submission.csv', index=False)\n"
   ],
   "id": "550c78ef081541b5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [00:18<00:00, 52.54it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 16.87it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'Fall'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 65\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# Imputation for missing values\u001B[39;00m\n\u001B[1;32m     64\u001B[0m imputer \u001B[38;5;241m=\u001B[39m SimpleImputer(strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmedian\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 65\u001B[0m train \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(imputer\u001B[38;5;241m.\u001B[39mfit_transform(train), columns\u001B[38;5;241m=\u001B[39mtrain\u001B[38;5;241m.\u001B[39mcolumns)\n\u001B[1;32m     66\u001B[0m test \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(imputer\u001B[38;5;241m.\u001B[39mtransform(test), columns\u001B[38;5;241m=\u001B[39mtest\u001B[38;5;241m.\u001B[39mcolumns)\n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# Train individual regressors for PCIAT01 to PCIAT20\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    319\u001B[0m         )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1098\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m   1083\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1084\u001B[0m             (\n\u001B[1;32m   1085\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis object (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) has a `transform`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1093\u001B[0m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[1;32m   1094\u001B[0m         )\n\u001B[1;32m   1096\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1097\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[1;32m   1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/impute/_base.py:421\u001B[0m, in \u001B[0;36mSimpleImputer.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    405\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit the imputer on `X`.\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \n\u001B[1;32m    407\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 421\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_input(X, in_fit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    423\u001B[0m     \u001B[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001B[39;00m\n\u001B[1;32m    424\u001B[0m     \u001B[38;5;66;03m# otherwise\u001B[39;00m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfill_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/impute/_base.py:348\u001B[0m, in \u001B[0;36mSimpleImputer._validate_input\u001B[0;34m(self, X, in_fit)\u001B[0m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not convert\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(ve):\n\u001B[1;32m    343\u001B[0m     new_ve \u001B[38;5;241m=\u001B[39m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    344\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot use \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m strategy with non-numeric data:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    345\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy, ve\n\u001B[1;32m    346\u001B[0m         )\n\u001B[1;32m    347\u001B[0m     )\n\u001B[0;32m--> 348\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m new_ve \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    350\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ve\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'Fall'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a0cd30ebaed2d415"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
