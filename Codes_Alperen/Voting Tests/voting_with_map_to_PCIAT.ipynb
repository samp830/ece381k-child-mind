{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import mode  # Add this import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "n_splits = 5\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/train.csv')\n",
    "test = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/test.csv')\n",
    "sample = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/sample_submission.csv')\n",
    "\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "\n",
    "train_ts = load_time_series(\"/Users/ad53533/Desktop/Applied ML/Project/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/Users/ad53533/Desktop/Applied ML/Project/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex', 'CGAS-Season', 'CGAS-CGAS_Score',\n",
    "                'Physical-Season', 'Physical-BMI', 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP', 'Fitness_Endurance-Season',\n",
    "                'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec', 'FGC-Season',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND', 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone',\n",
    "                'FGC-FGC_PU', 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR', 'FGC-FGC_SRR_Zone',\n",
    "                'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season', 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat',\n",
    "                'BIA-BIA_Frame_num', 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM', 'BIA-BIA_TBW', 'PAQ_A-Season',\n",
    "                'PAQ_A-PAQ_A_Total', 'PAQ_C-Season', 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T',\n",
    "                'PreInt_EduHx-Season', 'PreInt_EduHx-computerinternet_hoursday', 'sii', 'PCIAT-PCIAT_Total']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "\n",
    "train_sii = train['sii']\n",
    "train = train.dropna(subset='sii')\n",
    "train = train[featuresCols]\n",
    "\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "         'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "# Update categorical variables\n",
    "train = update(train)\n",
    "test = update(test)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "train = pd.get_dummies(train, columns=cat_c, drop_first=True)\n",
    "test = pd.get_dummies(test, columns=cat_c, drop_first=True)\n",
    "\n",
    "# Align train and test datasets to have the same columns\n",
    "train_sii = train['sii']\n",
    "train_PCIAT_Total = train['PCIAT-PCIAT_Total']\n",
    "train, test = train.drop(['sii', 'PCIAT-PCIAT_Total'], axis=1).align(test, join='outer', axis=1, fill_value=0)\n",
    "train['sii'] = train_sii\n",
    "train['PCIAT-PCIAT_Total'] = train_PCIAT_Total\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "\n",
    "def map_to_scaled_real(y_pred):\n",
    "    \"\"\"\n",
    "    Map values from 0-100 to a smaller real number with scaling in specific ranges.\n",
    "\n",
    "    Args:\n",
    "    - y_pred (array-like): Input values ranging from 0 to 100.\n",
    "\n",
    "    Returns:\n",
    "    - Scaled values as per the mapping logic.\n",
    "    \"\"\"\n",
    "    # Initialize the result array\n",
    "    scaled = np.zeros_like(y_pred, dtype=float)\n",
    "\n",
    "    # Apply the mapping logic\n",
    "    scaled = np.where((y_pred >= 0) & (y_pred <= 30), \n",
    "                      y_pred / 30,  # Scale 0-30 to 0-1\n",
    "                      scaled)\n",
    "    \n",
    "    scaled = np.where((y_pred > 30) & (y_pred <= 49),\n",
    "                      1 + (y_pred - 31) / (49 - 31),  # Scale 31-49 to 1-2\n",
    "                      scaled)\n",
    "    \n",
    "    scaled = np.where((y_pred > 50) & (y_pred <= 79),\n",
    "                      2 + (y_pred - 51) / (79 - 51),  # Scale 51-79 to 2-3\n",
    "                      scaled)\n",
    "    \n",
    "    scaled = np.where((y_pred > 80) & (y_pred <= 100),\n",
    "                      3 + (y_pred - 81) / (100 - 81),  # Scale 81-100 to 3-4\n",
    "                      scaled)\n",
    "\n",
    "    return scaled\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii', 'PCIAT-PCIAT_Total'], axis=1)\n",
    "    y = train['PCIAT-PCIAT_Total']\n",
    "    y_sii = np.select([y <= 30, y <= 49, y <= 79], [0, 1, 2], default=3)\n",
    "\n",
    "    SKF = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        y_train_mapped = map_to_scaled_real(y_train)\n",
    "        y_val_mapped = map_to_scaled_real(y_val)\n",
    "        \n",
    "        \n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train_mapped)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        # y_train_pred = map_to_scaled_real(y_train_pred)\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        # y_val_pred = map_to_scaled_real(y_val_pred)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "        \n",
    "        # # Calculate residuals\n",
    "        # residuals = y_train_mapped - y_train_pred\n",
    "        # # Plot the residuals\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # plt.scatter(y_train_pred, residuals, alpha=0.5, edgecolor='k')\n",
    "        # plt.axhline(0, color='red', linestyle='--', linewidth=1.5)\n",
    "        # plt.title(\"Residuals of y_train_pred with y_train\", fontsize=14)\n",
    "        # plt.xlabel(\"Predicted Values (y_train_pred)\", fontsize=12)\n",
    "        # plt.ylabel(\"Residuals (y_train - y_train_pred)\", fontsize=12)\n",
    "        # plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        # plt.show()\n",
    "        \n",
    "        \n",
    "        y_train_sii = np.select([y_train <= 30, y_train <= 49, y_train <= 79], [0, 1, 2], default=3)\n",
    "        train_kappa = quadratic_weighted_kappa(y_train_sii, y_train_pred.round(0).astype(int))\n",
    "        y_val_sii = np.select([y_val <= 30, y_val <= 49, y_val <= 79], [0, 1, 2], default=3)\n",
    "        val_kappa = quadratic_weighted_kappa(y_val_sii, y_val_pred.round(0).astype(int))\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_pred = model.predict(test_data)\n",
    "        # test_pred = np.select([test_pred <= 0.5, test_pred <= 1.5, test_pred <= 2.5], [0, 1, 2], default=3)\n",
    "        test_preds[:, fold] = test_pred\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y_sii, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tp_rounded = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    # tp_rounded = mode(test_preds, axis=1)[0].astype(int)\n",
    "    return tp_rounded\n",
    "\n",
    "\n",
    "# Imputation step: Filling missing values with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "ensemble = VotingRegressor(estimators=[\n",
    "    # Existing methods\n",
    "    ('lgb', Pipeline(steps=[('imputer', imputer), ('regressor', LGBMRegressor(random_state=SEED))])),\n",
    "    ('xgb', Pipeline(steps=[('imputer', imputer), ('regressor', XGBRegressor(random_state=SEED))])),\n",
    "    ('cat', Pipeline(steps=[('imputer', imputer), ('regressor', CatBoostRegressor(random_state=SEED, silent=True))])),\n",
    "    ('rf', Pipeline(steps=[('imputer', imputer), ('regressor', RandomForestRegressor(random_state=SEED))])),\n",
    "    ('gb', Pipeline(steps=[('imputer', imputer), ('regressor', GradientBoostingRegressor(random_state=SEED))])),\n",
    "    # New method\n",
    "    ('elasticnet', Pipeline(steps=[('imputer', imputer), ('regressor', ElasticNet(random_state=SEED))])),\n",
    "    ('svr', Pipeline(steps=[('imputer', imputer), ('regressor', SVR())])),\n",
    "    ('knn', Pipeline(steps=[('imputer', imputer), ('regressor', KNeighborsRegressor())])),\n",
    "    ('extratrees', Pipeline(steps=[('imputer', imputer), ('regressor', ExtraTreesRegressor(random_state=SEED))])),\n",
    "    ('ridge', Pipeline(steps=[('imputer', imputer), ('regressor', Ridge(alpha=1.0, random_state=SEED))]))\n",
    "])\n",
    "\n",
    "# Train the ensemble with the updated model pipeline\n",
    "predictions = TrainML(ensemble, test)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "sample['sii'] = predictions\n",
    "# sample.to_csv('submission.csv', index=False)"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [01:42<00:00, 20.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.4744\n",
      "Mean Validation QWK ---> 0.1518\n",
      "----> || Optimized QWK SCORE :: \u001B[36m\u001B[1m 0.013\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T00:27:52.994965Z",
     "start_time": "2024-11-24T00:27:52.975638Z"
    }
   },
   "cell_type": "code",
   "source": "y_sii",
   "id": "c0b1c0b5852379b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_sii' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m y_sii\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_sii' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:36:14.142200Z",
     "start_time": "2024-11-23T03:36:14.135194Z"
    }
   },
   "cell_type": "code",
   "source": "sample.to_csv('submission.csv', index=False)",
   "id": "9c5636c837553260",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:46:14.445958Z",
     "start_time": "2024-11-23T03:46:06.310123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEED = 42\n",
    "train = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/train.csv')\n",
    "test = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/test.csv')\n",
    "# Your train data here\n",
    "train = train.dropna(subset=['sii'])\n",
    "y_train = train['PCIAT-PCIAT_Total']\n",
    "train = train.drop(columns=[col for col in train.columns if 'PCIAT' in col])\n",
    "train = train.drop(columns=[col for col in train.columns if 'Season' in col])\n",
    "train = train.drop(columns=['id'])\n",
    "X_train = train.drop('sii', axis=1)\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "ensemble = VotingRegressor(estimators=[\n",
    "    ('lgb', Pipeline(steps=[('imputer', imputer), ('regressor', LGBMRegressor(random_state=SEED))])),\n",
    "    ('xgb', Pipeline(steps=[('imputer', imputer), ('regressor', XGBRegressor(random_state=SEED))])),\n",
    "    ('cat', Pipeline(steps=[('imputer', imputer), ('regressor', CatBoostRegressor(random_state=SEED, silent=True))])),\n",
    "    ('rf', Pipeline(steps=[('imputer', imputer), ('regressor', RandomForestRegressor(random_state=SEED))])),\n",
    "    ('gb', Pipeline(steps=[('imputer', imputer), ('regressor', GradientBoostingRegressor(random_state=SEED))])),\n",
    "    ('elasticnet', Pipeline(steps=[('imputer', imputer), ('regressor', ElasticNet(random_state=SEED))])),\n",
    "    ('svr', Pipeline(steps=[('imputer', imputer), ('regressor', SVR())])),\n",
    "    ('knn', Pipeline(steps=[('imputer', imputer), ('regressor', KNeighborsRegressor())])),\n",
    "    ('extratrees', Pipeline(steps=[('imputer', imputer), ('regressor', ExtraTreesRegressor(random_state=SEED))])),\n",
    "    ('ridge', Pipeline(steps=[('imputer', imputer), ('regressor', Ridge(alpha=1.0, random_state=SEED))]))\n",
    "])\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "first_sample_prediction = ensemble.predict([X_train.iloc[1]])\n",
    "print(first_sample_prediction)"
   ],
   "id": "20788a431437ccc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 2736, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 27.896199\n",
      "[11.81768039]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:50:08.266919Z",
     "start_time": "2024-11-23T03:50:00.112479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEED = 42\n",
    "train = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/train.csv')\n",
    "test = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/test.csv')\n",
    "train = train.dropna(subset=['sii'])\n",
    "y_train = train['PCIAT-PCIAT_Total']\n",
    "train = train.drop(columns=[col for col in train.columns if 'PCIAT' in col])\n",
    "train = train.drop(columns=[col for col in train.columns if 'Season' in col])\n",
    "train = train.drop(columns=['id'])\n",
    "X_train = train.drop('sii', axis=1)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ensemble = VotingRegressor(estimators=[\n",
    "    ('lgb', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', LGBMRegressor(random_state=SEED))])),\n",
    "    ('xgb', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', XGBRegressor(random_state=SEED))])),\n",
    "    ('cat', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', CatBoostRegressor(random_state=SEED, silent=True))])),\n",
    "    ('rf', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', RandomForestRegressor(random_state=SEED))])),\n",
    "    ('gb', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', GradientBoostingRegressor(random_state=SEED))])),\n",
    "    ('elasticnet', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', ElasticNet(random_state=SEED))])),\n",
    "    ('svr', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', SVR())])),\n",
    "    ('knn', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', KNeighborsRegressor())])),\n",
    "    ('extratrees', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', ExtraTreesRegressor(random_state=SEED))])),\n",
    "    ('ridge', Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('regressor', Ridge(alpha=1.0, random_state=SEED))]))\n",
    "])\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "first_sample_prediction = ensemble.predict([X_train.iloc[1]])\n",
    "print(first_sample_prediction)"
   ],
   "id": "f3c07b66a5ddce9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5837\n",
      "[LightGBM] [Info] Number of data points in the train set: 2736, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 27.896199\n",
      "[10.39443045]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:50:12.849803Z",
     "start_time": "2024-11-23T03:50:12.845198Z"
    }
   },
   "cell_type": "code",
   "source": "y_train[0]",
   "id": "f86d5cee9ff1d8cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:50:19.628906Z",
     "start_time": "2024-11-23T03:50:19.603800Z"
    }
   },
   "cell_type": "code",
   "source": "ensemble.predict([X_train.iloc[3]])",
   "id": "7a0f5a020ffd1b22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.05859101])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:50:23.713489Z",
     "start_time": "2024-11-23T03:50:23.674652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = test.drop(columns=[col for col in test.columns if 'PCIAT' in col])\n",
    "test = test.drop(columns=[col for col in test.columns if 'Season' in col])\n",
    "test = test.drop(columns=['id'])\n",
    "\n",
    "predictions = ensemble.predict(test)"
   ],
   "id": "9bfae5a1c157df17",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:50:24.430414Z",
     "start_time": "2024-11-23T03:50:24.425764Z"
    }
   },
   "cell_type": "code",
   "source": "predictions",
   "id": "9f9836610979a7de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.29778349, 10.39443045, 29.25355105, 30.05859101, 29.99468139,\n",
       "       30.10793945, 25.45122911, 25.14797596, 43.20253518, 27.48883597,\n",
       "       32.33671887, 24.48992905, 33.83388519, 34.1026294 , 39.6151773 ,\n",
       "       39.96327622,  6.08904921, 23.13830905, 28.00432845, 35.72834761])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:50:27.878358Z",
     "start_time": "2024-11-23T03:50:27.875097Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = np.select([predictions <= 30, predictions <= 49, predictions <= 79], [0, 1, 2], default=3)",
   "id": "1abb40c6d687c37c",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:50:28.642793Z",
     "start_time": "2024-11-23T03:50:28.638484Z"
    }
   },
   "cell_type": "code",
   "source": "predictions",
   "id": "6d3d8c7ecc91dd2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b3851d1bf51dbc58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
