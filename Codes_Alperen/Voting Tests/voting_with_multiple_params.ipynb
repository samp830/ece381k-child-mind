{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:28:27.648139Z",
     "start_time": "2024-11-23T03:28:06.478468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "SEED = 42\n",
    "n_splits = 5\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/train.csv')\n",
    "test = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/test.csv')\n",
    "sample = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/sample_submission.csv')\n",
    "\n",
    "print(sample)\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "\n",
    "train_ts = load_time_series(\"/Users/ad53533/Desktop/Applied ML/Project/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/Users/ad53533/Desktop/Applied ML/Project/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex', 'CGAS-Season', 'CGAS-CGAS_Score',\n",
    "                'Physical-Season', 'Physical-BMI', 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP', 'Fitness_Endurance-Season',\n",
    "                'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec', 'FGC-Season',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND', 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone',\n",
    "                'FGC-FGC_PU', 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR', 'FGC-FGC_SRR_Zone',\n",
    "                'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season', 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat',\n",
    "                'BIA-BIA_Frame_num', 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM', 'BIA-BIA_TBW', 'PAQ_A-Season',\n",
    "                'PAQ_A-PAQ_A_Total', 'PAQ_C-Season', 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T',\n",
    "                'PreInt_EduHx-Season', 'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "         'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "# Update categorical variables\n",
    "train = update(train)\n",
    "test = update(test)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "train = pd.get_dummies(train, columns=cat_c, drop_first=True)\n",
    "test = pd.get_dummies(test, columns=cat_c, drop_first=True)\n",
    "\n",
    "# Align train and test datasets to have the same columns\n",
    "train_sii = train['sii']\n",
    "train, test = train.drop('sii', axis=1).align(test, join='outer', axis=1, fill_value=0)\n",
    "train['sii'] = train_sii\n",
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "# for col in cat_c:\n",
    "#     mapping = create_mapping(col, train)\n",
    "#     mappingTe = create_mapping(col, test)\n",
    "#     \n",
    "#     train[col] = train[col].replace(mapping).astype(int)\n",
    "#     test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tp_rounded = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "\n",
    "    return tp_rounded\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Imputation step: Filling missing values with the median\n",
    "imputer = SimpleImputer(strategy='median')"
   ],
   "id": "ff0130658693da15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  sii\n",
      "0   00008ff9    0\n",
      "1   000fd460    1\n",
      "2   00105258    2\n",
      "3   00115b9f    3\n",
      "4   0016bb22    0\n",
      "5   001f3379    1\n",
      "6   0038ba98    2\n",
      "7   0068a485    3\n",
      "8   0069fbed    0\n",
      "9   0083e397    1\n",
      "10  0087dd65    2\n",
      "11  00abe655    3\n",
      "12  00ae59c9    0\n",
      "13  00af6387    1\n",
      "14  00bd4359    2\n",
      "15  00c0cd71    3\n",
      "16  00d56d4b    0\n",
      "17  00d9913d    1\n",
      "18  00e6167c    2\n",
      "19  00ebc35d    3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [00:20<00:00, 47.59it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 16.36it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def run_with_parameters(params_list, test_data):\n",
    "    \"\"\"\n",
    "    Run the training multiple times with different parameters\n",
    "    and aggregate the predictions using majority voting.\n",
    "    \n",
    "    Args:\n",
    "    - params_list: A list of parameter dictionaries for regressors.\n",
    "    - test_data: The test dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - Final predictions based on majority voting.\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "\n",
    "    for params in params_list:\n",
    "        # Define the ensemble with updated parameters\n",
    "        ensemble = VotingRegressor(estimators=[\n",
    "            ('lgb', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('regressor', LGBMRegressor(**params.get('lgb', {}), random_state=SEED))\n",
    "            ])),\n",
    "            ('xgb', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('regressor', XGBRegressor(**params.get('xgb', {}), random_state=SEED))\n",
    "            ])),\n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('regressor', CatBoostRegressor(**params.get('cat', {}), random_state=SEED, silent=True))\n",
    "            ])),\n",
    "            ('rf', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('regressor', RandomForestRegressor(**params.get('rf', {}), random_state=SEED))\n",
    "            ])),\n",
    "            ('gb', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('regressor', GradientBoostingRegressor(**params.get('gb', {}), random_state=SEED))\n",
    "            ]))\n",
    "        ])\n",
    "\n",
    "        # Train the model and get predictions\n",
    "        predictions = TrainML(ensemble, test_data)\n",
    "        all_predictions.append(predictions)\n",
    "\n",
    "    # Perform majority voting for the final predictions\n",
    "    final_predictions = np.array(all_predictions).T\n",
    "    majority_vote = [Counter(row).most_common(1)[0][0] for row in final_predictions]\n",
    "\n",
    "    return majority_vote\n",
    "\n",
    "# Define parameter sets for multiple runs\n",
    "parameter_sets = [\n",
    "    {\n",
    "        'lgb': {'learning_rate': 0.1, 'n_estimators': 100},\n",
    "        'xgb': {'learning_rate': 0.1, 'n_estimators': 100},\n",
    "        'cat': {'depth': 6, 'iterations': 100},\n",
    "        'rf': {'n_estimators': 100, 'max_depth': 10},\n",
    "        'gb': {'n_estimators': 100, 'learning_rate': 0.1}\n",
    "    },\n",
    "    {\n",
    "        'lgb': {'learning_rate': 0.05, 'n_estimators': 150},\n",
    "        'xgb': {'learning_rate': 0.05, 'n_estimators': 150},\n",
    "        'cat': {'depth': 8, 'iterations': 150},\n",
    "        'rf': {'n_estimators': 150, 'max_depth': 12},\n",
    "        'gb': {'n_estimators': 150, 'learning_rate': 0.05}\n",
    "    },\n",
    "    {\n",
    "        'lgb': {'learning_rate': 0.01, 'n_estimators': 200},\n",
    "        'xgb': {'learning_rate': 0.01, 'n_estimators': 200},\n",
    "        'cat': {'depth': 10, 'iterations': 200},\n",
    "        'rf': {'n_estimators': 200, 'max_depth': 15},\n",
    "        'gb': {'n_estimators': 200, 'learning_rate': 0.01}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run the process and get the final predictions\n",
    "final_predictions = run_with_parameters(parameter_sets, test)\n",
    "\n",
    "# Save the final predictions to a CSV file\n",
    "sample['sii'] = final_predictions\n",
    "sample.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Final predictions saved to submission.csv\")"
   ],
   "id": "e9d8582c9b0be4ac",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [01:53<00:00, 22.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.7618\n",
      "Mean Validation QWK ---> 0.3532\n",
      "----> || Optimized QWK SCORE :: \u001B[36m\u001B[1m 0.460\u001B[0m\n",
      "Final predictions saved to submission_majority_vote.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a43f9186915c37ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
