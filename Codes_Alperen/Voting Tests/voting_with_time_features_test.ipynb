{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "SEED = 42\n",
    "n_splits = 5\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/train.csv')\n",
    "test = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/test.csv')\n",
    "sample = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/sample_submission.csv')\n",
    "\n",
    "print(sample)\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "\n",
    "train_ts = load_time_series(\"/Users/ad53533/Desktop/Applied ML/Project/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/Users/ad53533/Desktop/Applied ML/Project/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# # Assuming 'train' is your DataFrame\n",
    "\n",
    "# # Step 1: Create the KNN imputer\n",
    "# imputer = KNNImputer(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "\n",
    "# # Step 2: Select numeric columns and fit the imputer\n",
    "# numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "# imputed_data = imputer.fit_transform(train[numeric_cols])\n",
    "\n",
    "# # Step 3: Create a new DataFrame with the imputed values\n",
    "# train_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "\n",
    "# # Step 4: Convert the 'sii' column back to integers\n",
    "# train_imputed['sii'] = train_imputed['sii'].round().astype(int)\n",
    "\n",
    "# # If there are other columns to retain, you can merge them back\n",
    "# for col in train.columns:\n",
    "#     if col not in numeric_cols:\n",
    "#         train_imputed[col] = train[col]\n",
    "\n",
    "# # Now, check if 'sii' has been filled and is of integer type\n",
    "# print(train_imputed['sii'].isna().sum())  # Should be 0 if all NaNs were filled\n",
    "# print(train_imputed['sii'].dtype)  # Should show 'int'\n",
    "\n",
    "# train_imputed['sii']=train['sii']\n",
    "\n",
    "# train=train_imputed\n",
    "\n",
    "#####\n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex', 'CGAS-Season', 'CGAS-CGAS_Score',\n",
    "                'Physical-Season', 'Physical-BMI', 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP', 'Fitness_Endurance-Season',\n",
    "                'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec', 'FGC-Season',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND', 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone',\n",
    "                'FGC-FGC_PU', 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR', 'FGC-FGC_SRR_Zone',\n",
    "                'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season', 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat',\n",
    "                'BIA-BIA_Frame_num', 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM', 'BIA-BIA_TBW', 'PAQ_A-Season',\n",
    "                'PAQ_A-PAQ_A_Total', 'PAQ_C-Season', 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T',\n",
    "                'PreInt_EduHx-Season', 'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "train = train.dropna(subset='sii')\n",
    "train_PCIAT_Total = train['PCIAT-PCIAT_Total']\n",
    "train = train[featuresCols]\n",
    "\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "         'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "train = update(train)\n",
    "test = update(test)\n",
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "for col in cat_c:\n",
    "    mapping = create_mapping(col, train)\n",
    "    mappingTe = create_mapping(col, test)\n",
    "    \n",
    "    train[col] = train[col].replace(mapping).astype(int)\n",
    "    test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train_PCIAT_Total\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_train_pred = np.select([y_train_pred <= 30, y_train_pred <= 49, y_train_pred <= 79], [0, 1, 2], default=3)\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred = np.select([y_val_pred <= 30, y_val_pred <= 49, y_val_pred <= 79], [0, 1, 2], default=3)\n",
    "        \n",
    "        \n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "        \n",
    "        y_train_sii = np.select([y_train <= 30, y_train <= 49, y_train <= 79], [0, 1, 2], default=3)\n",
    "        train_kappa = quadratic_weighted_kappa(y_train_sii, y_train_pred.round(0).astype(int))\n",
    "        y_val_sii = np.select([y_val <= 30, y_val <= 49, y_val <= 79], [0, 1, 2], default=3)\n",
    "        val_kappa = quadratic_weighted_kappa(y_val_sii, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_pred = model.predict(test_data)\n",
    "        test_preds[:, fold] = np.select([test_pred <= 30, test_pred <= 49, test_pred <= 79], [0, 1, 2], default=3)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    y_sii = np.select([y <= 30, y <= 49, y <= 79], [0, 1, 2], default=3)\n",
    "    tKappa = quadratic_weighted_kappa(y_sii, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tp_rounded = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "\n",
    "    return tp_rounded\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Imputation step: Filling missing values with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Updating the ensemble to include the RandomForest and GradientBoosting models\n",
    "ensemble = VotingRegressor(estimators=[\n",
    "    ('lgb', Pipeline(steps=[('imputer', imputer), ('regressor', LGBMRegressor(random_state=SEED))])),\n",
    "    ('xgb', Pipeline(steps=[('imputer', imputer), ('regressor', XGBRegressor(random_state=SEED))])),\n",
    "    ('cat', Pipeline(steps=[('imputer', imputer), ('regressor', CatBoostRegressor(random_state=SEED, silent=True))])),\n",
    "    ('rf', Pipeline(steps=[('imputer', imputer), ('regressor', RandomForestRegressor(random_state=SEED))])),\n",
    "    ('gb', Pipeline(steps=[('imputer', imputer), ('regressor', GradientBoostingRegressor(random_state=SEED))]))\n",
    "])\n",
    "\n",
    "# Train the ensemble with the updated model pipeline\n",
    "predictions = TrainML(ensemble, test)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "sample['sii'] = predictions\n",
    "# sample.to_csv('submission.csv', index=False)"
   ],
   "id": "10a7e65ee34cf5da",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [01:03<00:00, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.8427\n",
      "Mean Validation QWK ---> 0.3954\n",
      "----> || Optimized QWK SCORE :: \u001B[36m\u001B[1m 0.395\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:19:29.523967Z",
     "start_time": "2024-11-19T23:19:29.516872Z"
    }
   },
   "cell_type": "code",
   "source": "sample.to_csv('submission.csv', index=False)",
   "id": "f9dfee980329003d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T00:16:16.602122Z",
     "start_time": "2024-11-20T00:16:16.593841Z"
    }
   },
   "cell_type": "code",
   "source": "np.size(sample)",
   "id": "97406b10e914fc69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T00:16:23.527848Z",
     "start_time": "2024-11-20T00:16:23.524982Z"
    }
   },
   "cell_type": "code",
   "source": "np.size(test)",
   "id": "fb1a082b893268a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3080"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:16:57.480067Z",
     "start_time": "2024-11-20T02:16:57.476100Z"
    }
   },
   "cell_type": "code",
   "source": "predictions",
   "id": "1e625e88e1b15b17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "17ee8e3b1378864b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
