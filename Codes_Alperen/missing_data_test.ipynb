{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:59:54.567998Z",
     "start_time": "2024-12-03T23:59:54.544568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Load datasets\n",
    "train = pd.read_csv('/Users/ad53533/Desktop/Applied ML/Project/train.csv')\n",
    "missing_sii_rows = train['sii'].isnull().sum()\n",
    "print(missing_sii_rows)"
   ],
   "id": "2d49d4469e9d82c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:00:52.269995Z",
     "start_time": "2024-12-04T00:00:52.266805Z"
    }
   },
   "cell_type": "code",
   "source": "len(train)",
   "id": "39e1e64b993c3db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3960"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:21:21.413317Z",
     "start_time": "2024-12-04T00:21:20.535651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Step 1: Drop 'id' feature and assign 'missing' to missing categorical values\n",
    "train = train.drop(columns=['id'], errors='ignore')  # Drop 'id' if it exists\n",
    "categorical_features = train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Fill missing values in categorical features with 'missing'\n",
    "train[categorical_features] = train[categorical_features].fillna('missing')\n",
    "\n",
    "# Dummy encode the categorical variables\n",
    "train = pd.get_dummies(train, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Step 2: Drop rows with missing 'sii' values\n",
    "# Get rows with missing 'sii' values\n",
    "missing_sii_rows_df = train[train['sii'].isnull()]\n",
    "train = train.dropna(subset=['sii'], axis=0)\n",
    "\n",
    "# Step 3: Group by 'sii' values and impute each group individually\n",
    "groups = train.groupby('sii')\n",
    "imputed_groups = []\n",
    "\n",
    "for sii_value, group in groups:\n",
    "    # Drop 'sii' column temporarily as it doesn't need imputation\n",
    "    sii_column = group['sii']\n",
    "    group = group.drop(columns=['sii'])\n",
    "    \n",
    "    # Apply KNN Imputer\n",
    "    imputer = KNNImputer(n_neighbors=5)  # Adjust `n_neighbors` as needed\n",
    "    imputed_data = imputer.fit_transform(group)\n",
    "    \n",
    "    # Recreate DataFrame with imputed data\n",
    "    imputed_group = pd.DataFrame(imputed_data, columns=group.columns, index=group.index)\n",
    "    imputed_group['sii'] = sii_column  # Add 'sii' column back\n",
    "    imputed_groups.append(imputed_group)\n",
    "\n",
    "# Step 4: Concatenate all groups back into a single DataFrame\n",
    "imputed_train = pd.concat(imputed_groups)\n",
    "\n",
    "# The final DataFrame `imputed_train` contains:\n",
    "# - Imputed numerical data\n",
    "# - Dummy-encoded categorical data\n",
    "# - 'sii' values retained\n"
   ],
   "id": "313441ca90e7c3ef",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:40:37.224031Z",
     "start_time": "2024-12-04T00:40:36.423695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Assuming `imputed_train` is your dataset and `new_vector` is the incoming vector with missing values\n",
    "\n",
    "# Step 1: Ensure the new vector is a DataFrame with the same columns as the dataset\n",
    "new_vector_df = pd.DataFrame(missing_sii_rows_df, columns=imputed_train.columns)\n",
    "\n",
    "# Step 2: Handle missing values in the new vector using the same KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=3)  # Use the same imputer as before\n",
    "combined_data = pd.concat([imputed_train, new_vector_df], ignore_index=True)\n",
    "imputed_combined = imputer.fit_transform(combined_data)\n",
    "\n",
    "test_indices = range(1000)\n",
    "count = 0\n",
    "for indices in test_indices:\n",
    "    \n",
    "\n",
    "    # Extract the imputed new vector\n",
    "    imputed_new_vector = imputed_combined[-indices]  # The last row corresponds to the new vector\n",
    "    \n",
    "    # Step 3: Compute distances\n",
    "    distances = euclidean_distances(imputed_combined[:-1], [imputed_new_vector])  # Exclude the new vector from the dataset\n",
    "    \n",
    "    # Step 4: Find the 5 nearest neighbors\n",
    "    nearest_indices = np.argsort(distances.flatten())[:3]\n",
    "    nearest_distances = distances.flatten()[nearest_indices]\n",
    "    \n",
    "    # # Print results\n",
    "    # print(\"Indices of the 5 nearest neighbors:\", nearest_indices)\n",
    "    # print(\"Distances to the 5 nearest neighbors:\", nearest_distances)\n",
    "    \n",
    "    # Optionally, you can retrieve the corresponding rows in the original DataFrame\n",
    "    nearest_neighbors = imputed_train.iloc[nearest_indices]\n",
    "    nearest_sii = nearest_neighbors['sii']\n",
    "    sii_values = nearest_neighbors['sii'].unique()\n",
    "    if len(sii_values) == 1:  # If all 'sii' values are the same\n",
    "        # print(f\"All nearest neighbors have the same 'sii' value: {sii_values[0]}\")\n",
    "        count = count + 1\n",
    "    # print(\"Nearest Neighbors DataFrame:\")\n",
    "    # print(nearest_neighbors)\n",
    "print(count)\n"
   ],
   "id": "3fdc9c2155fbf767",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:36:32.619609Z",
     "start_time": "2024-12-04T00:36:32.616198Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5a36d5f9b7e821df",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:34:05.726427Z",
     "start_time": "2024-12-04T00:34:05.722975Z"
    }
   },
   "cell_type": "code",
   "source": "range(10)",
   "id": "f33610944db65dde",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "446f4eb6c6f33892"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
